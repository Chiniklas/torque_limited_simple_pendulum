transfer learning from a working agent based on undamped system
using softbinary_with repellor reward

# pendulum parameters
mass = 0.57288
length = 0.5
inertia = mass*length**2
damping = 0.10
gravity = 9.81
coulomb_fric = 0.0
torque_limit = 1.5

# environment parameters
dt = 0.01
integrator = "runge_kutta"
max_steps = 1000
reward_type = "soft_binary_with_repellor"

target = [np.pi, 0]
target_epsilon = [0.1, 0.1]
random_init = "False"

# training parameters
learning_rate = 0.0003
training_timesteps = 1e6
reward_threshold = 1000
eval_frequency = 10000
n_eval_episodes = 20